{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K7cyZ5WNizs8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from gensim.models import FastText\n",
        "from gensim.utils import tokenize\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import multiprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poster = pd.read_csv('./database_posters.csv')\n",
        "dolls = pd.read_csv('./database_dolls.csv')\n",
        "\n",
        "merge_df = pd.concat([poster, dolls], ignore_index=True)\n",
        "merge_df.to_csv('database_md.csv', index=False)"
      ],
      "metadata": {
        "id": "cyportTtsQtr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = ['./database_albums.csv', './database_photocards.csv', './database_md.csv']\n",
        "accuracies = 0"
      ],
      "metadata": {
        "id": "6uUvY1Avswcj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files:\n",
        "  df = pd.read_csv(file)\n",
        "  df = df.sample(frac=1).reset_index(drop=True)  # 셔플\n",
        "\n",
        "  lower_df = df[['title', 'price']]\n",
        "  lower_df = lower_df.apply(lambda x: x.str.lower() if x.dtype == 'object' else x)\n",
        "\n",
        "  data = df['title']\n",
        "  gensim_input = [text.rstrip().lower() for text in data]\n",
        "\n",
        "    # 학습 데이터와 평가 데이터 분리\n",
        "  train_data, test_data, train_labels, test_labels = train_test_split(df['title'], df['price'], test_size=0.2)\n",
        "\n",
        "  train_data = list(train_data)\n",
        "  test_data = list(test_data)\n",
        "  test_labels = list(test_labels)\n",
        "\n",
        "  # FastText 모델 학습\n",
        "  ft_model = FastText(vector_size=100, min_count=1, window=5, workers=multiprocessing.cpu_count(), sg=1)\n",
        "  ft_model.build_vocab(corpus_iterable=[list(tokenize(text)) for text in train_data])\n",
        "  ft_model.train(corpus_iterable=[list(tokenize(text)) for text in train_data], total_examples=len(train_data), epochs=10)\n",
        "\n",
        "  #################################### 예측값 및 정확도 측정 ####################################\n",
        "  accurate_predictions = 0\n",
        "  total_predictions = 0\n",
        "  idx = 0\n",
        "\n",
        "  for text in test_data:\n",
        "      y_pred = []\n",
        "      query = text.lower()\n",
        "      query_vec = np.mean([ft_model.wv[word] for word in query.split()], axis=0)\n",
        "\n",
        "      # 가장 유사한 문장을 찾습니다.\n",
        "      similar_sentences = []\n",
        "      for sentence in train_data:\n",
        "          sentence_vec = np.mean([ft_model.wv[word] for word in sentence.split()], axis=0)\n",
        "          similarity = cosine_similarity([query_vec], [sentence_vec])[0][0]\n",
        "          similar_sentences.append((sentence, similarity))\n",
        "\n",
        "      # 유사도가 높은 순으로 정렬한 후, 상위 2개 문장을 출력합니다.\n",
        "      similar_sentences = sorted(similar_sentences, key=lambda x: x[1], reverse=True)[:2]\n",
        "      for sentence_df in similar_sentences:\n",
        "          sentence = sentence_df[0]\n",
        "          price_df = lower_df[lower_df['title'] == sentence.lower()]\n",
        "          if price_df.empty:\n",
        "              continue\n",
        "          price = price_df['price'].values\n",
        "          for p in price:\n",
        "              y_pred.append(p)\n",
        "\n",
        "      maxPred = max(y_pred) if y_pred else float('-inf')\n",
        "      minPred = min(y_pred) if y_pred else float('inf')\n",
        "\n",
        "      true_label = test_labels[idx]\n",
        "\n",
        "      if minPred <= true_label <= maxPred:\n",
        "          accurate_predictions += 1\n",
        "\n",
        "      total_predictions += 1\n",
        "      idx += 1\n",
        "      #print(\"acc: \", accurate_predictions, \" total: \", total_predictions)\n",
        "\n",
        "  accuracy = accurate_predictions / total_predictions\n",
        "  accuracies += accuracy\n",
        "\n",
        "totalAccuracy = accuracies / 3"
      ],
      "metadata": {
        "id": "ttl4ktzyi_v5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {totalAccuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kxtl0fUjK1b",
        "outputId": "3d26e600-c952-4caa-c3ec-dba1ec1ed9c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4398\n"
          ]
        }
      ]
    }
  ]
}